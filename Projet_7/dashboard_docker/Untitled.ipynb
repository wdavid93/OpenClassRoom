{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af7dfa0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting streamlit\n",
      "  Obtaining dependency information for streamlit from https://files.pythonhosted.org/packages/34/01/9d1460a6e71d6226e1f5c5053de20758c41100c5c15abb73551273a96fb8/streamlit-1.27.2-py2.py3-none-any.whl.metadata\n",
      "  Downloading streamlit-1.27.2-py2.py3-none-any.whl.metadata (8.1 kB)\n",
      "Collecting altair<6,>=4.0 (from streamlit)\n",
      "  Obtaining dependency information for altair<6,>=4.0 from https://files.pythonhosted.org/packages/17/16/b12fca347ff9d062e3c44ad9641d2ec50364570a059f3078ada3a5119d7a/altair-5.1.2-py3-none-any.whl.metadata\n",
      "  Downloading altair-5.1.2-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting blinker<2,>=1.0.0 (from streamlit)\n",
      "  Obtaining dependency information for blinker<2,>=1.0.0 from https://files.pythonhosted.org/packages/bf/2b/11bcedb7dee4923253a4a21bae3be854bcc4f06295bd827756352016d97c/blinker-1.6.3-py3-none-any.whl.metadata\n",
      "  Downloading blinker-1.6.3-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from streamlit) (5.3.1)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from streamlit) (8.0.4)\n",
      "Requirement already satisfied: importlib-metadata<7,>=1.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from streamlit) (6.0.0)\n",
      "Requirement already satisfied: numpy<2,>=1.19.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from streamlit) (1.24.3)\n",
      "Requirement already satisfied: packaging<24,>=16.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from streamlit) (23.0)\n",
      "Requirement already satisfied: pandas<3,>=1.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from streamlit) (1.5.3)\n",
      "Requirement already satisfied: pillow<11,>=7.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from streamlit) (9.4.0)\n",
      "Requirement already satisfied: protobuf<5,>=3.20 in c:\\programdata\\anaconda3\\lib\\site-packages (from streamlit) (4.24.3)\n",
      "Requirement already satisfied: pyarrow>=6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from streamlit) (11.0.0)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.7.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from streamlit) (2.8.2)\n",
      "Requirement already satisfied: requests<3,>=2.27 in c:\\programdata\\anaconda3\\lib\\site-packages (from streamlit) (2.31.0)\n",
      "Collecting rich<14,>=10.14.0 (from streamlit)\n",
      "  Obtaining dependency information for rich<14,>=10.14.0 from https://files.pythonhosted.org/packages/be/2a/4e62ff633612f746f88618852a626bbe24226eba5e7ac90e91dcfd6a414e/rich-13.6.0-py3-none-any.whl.metadata\n",
      "  Downloading rich-13.6.0-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: tenacity<9,>=8.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from streamlit) (8.2.2)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from streamlit) (4.5.0)\n",
      "Collecting tzlocal<6,>=1.1 (from streamlit)\n",
      "  Obtaining dependency information for tzlocal<6,>=1.1 from https://files.pythonhosted.org/packages/1c/af/343114b3ed9500b46108b56569b31a3108d3669d4fd063d9640e2c36cd57/tzlocal-5.1-py3-none-any.whl.metadata\n",
      "  Downloading tzlocal-5.1-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting validators<1,>=0.2 (from streamlit)\n",
      "  Obtaining dependency information for validators<1,>=0.2 from https://files.pythonhosted.org/packages/3a/0c/785d317eea99c3739821718f118c70537639aa43f96bfa1d83a71f68eaf6/validators-0.22.0-py3-none-any.whl.metadata\n",
      "  Downloading validators-0.22.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n",
      "  Obtaining dependency information for gitpython!=3.1.19,<4,>=3.0.7 from https://files.pythonhosted.org/packages/8a/7e/20f7e45878b5aed34320fbeeae8f78acc806e7bd708d00b1c6e64b016f5b/GitPython-3.1.37-py3-none-any.whl.metadata\n",
      "  Downloading GitPython-3.1.37-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
      "  Downloading pydeck-0.8.1b0-py2.py3-none-any.whl (4.8 MB)\n",
      "     ---------------------------------------- 0.0/4.8 MB ? eta -:--:--\n",
      "     --------------- ------------------------ 1.9/4.8 MB 40.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  4.8/4.8 MB 61.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 4.8/4.8 MB 43.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from streamlit) (6.3.2)\n",
      "Requirement already satisfied: watchdog>=2.1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from streamlit) (2.1.6)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from altair<6,>=4.0->streamlit) (3.1.2)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from altair<6,>=4.0->streamlit) (4.17.3)\n",
      "Requirement already satisfied: toolz in c:\\programdata\\anaconda3\\lib\\site-packages (from altair<6,>=4.0->streamlit) (0.12.0)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from click<9,>=7.0->streamlit) (0.4.6)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
      "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
      "     ---------------------------------------- 0.0/62.7 kB ? eta -:--:--\n",
      "     ---------------------------------------- 62.7/62.7 kB ? eta 0:00:00\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from importlib-metadata<7,>=1.4->streamlit) (3.11.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas<3,>=1.3.0->streamlit) (2022.7)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil<3,>=2.7.3->streamlit) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->streamlit) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2023.7.22)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from rich<14,>=10.14.0->streamlit) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from rich<14,>=10.14.0->streamlit) (2.15.1)\n",
      "Collecting tzdata (from tzlocal<6,>=1.1->streamlit)\n",
      "  Using cached tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
      "  Obtaining dependency information for smmap<6,>=3.0.1 from https://files.pythonhosted.org/packages/a7/a5/10f97f73544edcdef54409f1d839f6049a0d79df68adbc1ceb24d1aaca42/smmap-5.0.1-py3-none-any.whl.metadata\n",
      "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.1)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (22.1.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.0)\n",
      "Downloading streamlit-1.27.2-py2.py3-none-any.whl (7.6 MB)\n",
      "   ---------------------------------------- 0.0/7.6 MB ? eta -:--:--\n",
      "   ---------------------- ----------------- 4.3/7.6 MB 139.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  7.6/7.6 MB 97.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 7.6/7.6 MB 69.1 MB/s eta 0:00:00\n",
      "Downloading altair-5.1.2-py3-none-any.whl (516 kB)\n",
      "   ---------------------------------------- 0.0/516.2 kB ? eta -:--:--\n",
      "   --------------------------------------- 516.2/516.2 kB 33.7 MB/s eta 0:00:00\n",
      "Downloading blinker-1.6.3-py3-none-any.whl (13 kB)\n",
      "Downloading GitPython-3.1.37-py3-none-any.whl (190 kB)\n",
      "   ---------------------------------------- 0.0/190.0 kB ? eta -:--:--\n",
      "   --------------------------------------- 190.0/190.0 kB 12.0 MB/s eta 0:00:00\n",
      "Downloading rich-13.6.0-py3-none-any.whl (239 kB)\n",
      "   ---------------------------------------- 0.0/239.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 239.8/239.8 kB ? eta 0:00:00\n",
      "Downloading tzlocal-5.1-py3-none-any.whl (21 kB)\n",
      "Downloading validators-0.22.0-py3-none-any.whl (26 kB)\n",
      "Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: validators, tzdata, smmap, blinker, tzlocal, rich, pydeck, gitdb, gitpython, altair, streamlit\n",
      "Successfully installed altair-5.1.2 blinker-1.6.3 gitdb-4.0.10 gitpython-3.1.37 pydeck-0.8.1b0 rich-13.6.0 smmap-5.0.1 streamlit-1.27.2 tzdata-2023.3 tzlocal-5.1 validators-0.22.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script streamlit.exe is installed in 'C:\\Users\\Zbook\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "!pip install streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb258258",
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalHashError",
     "evalue": "module '__main__' has no attribute '__file__'\n\nWhile caching the body of `init_api()`, Streamlit encountered an\nobject of type `builtins.function`, which it does not know how to hash.\n\n**In this specific case, it's very likely you found a Streamlit bug so please\n[file a bug report here.]\n(https://github.com/streamlit/streamlit/issues/new/choose)**\n\nIn the meantime, you can try bypassing this error by registering a custom\nhash function via the `hash_funcs` keyword in @st.cache(). For example:\n\n```\n@st.cache(hash_funcs={builtins.function: my_hash_func})\ndef my_func(...):\n    ...\n```\n\nIf you don't know where the object of type `builtins.function` is coming\nfrom, try looking at the hash chain below for an object that you do recognize,\nthen pass that to `hash_funcs` instead:\n\n```\nObject of type builtins.function: <function init_api at 0x00000160459B39C0>\n```\n\nPlease see the `hash_funcs` [documentation](https://docs.streamlit.io/library/advanced-features/caching#the-hash_funcs-parameter)\nfor more details.\n            ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\streamlit\\runtime\\legacy_caching\\hashing.py:360\u001b[0m, in \u001b[0;36m_CodeHasher.to_bytes\u001b[1;34m(self, obj, context)\u001b[0m\n\u001b[0;32m    358\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    359\u001b[0m     \u001b[38;5;66;03m# Hash the input\u001b[39;00m\n\u001b[1;32m--> 360\u001b[0m     b \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (tname, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_to_bytes(obj, context))\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;66;03m# Hmmm... It's possible that the size calculation is wrong. When we\u001b[39;00m\n\u001b[0;32m    363\u001b[0m     \u001b[38;5;66;03m# call to_bytes inside _to_bytes things get double-counted.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\streamlit\\runtime\\legacy_caching\\hashing.py:626\u001b[0m, in \u001b[0;36m_CodeHasher._to_bytes\u001b[1;34m(self, obj, context)\u001b[0m\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m code \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 626\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file_should_be_hashed(code\u001b[38;5;241m.\u001b[39mco_filename):\n\u001b[0;32m    627\u001b[0m     context \u001b[38;5;241m=\u001b[39m _get_context(obj)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\streamlit\\runtime\\legacy_caching\\hashing.py:402\u001b[0m, in \u001b[0;36m_CodeHasher._file_should_be_hashed\u001b[1;34m(self, filename)\u001b[0m\n\u001b[0;32m    400\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m file_util\u001b[38;5;241m.\u001b[39mfile_is_in_folder_glob(\n\u001b[1;32m--> 402\u001b[0m     filepath, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_main_script_directory()\n\u001b[0;32m    403\u001b[0m ) \u001b[38;5;129;01mor\u001b[39;00m file_util\u001b[38;5;241m.\u001b[39mfile_in_pythonpath(filepath)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\streamlit\\runtime\\legacy_caching\\hashing.py:714\u001b[0m, in \u001b[0;36m_CodeHasher._get_main_script_directory\u001b[1;34m()\u001b[0m\n\u001b[0;32m    712\u001b[0m \u001b[38;5;66;03m# This works because we set __main__.__file__ to the\u001b[39;00m\n\u001b[0;32m    713\u001b[0m \u001b[38;5;66;03m# script path in ScriptRunner.\u001b[39;00m\n\u001b[1;32m--> 714\u001b[0m abs_main_path \u001b[38;5;241m=\u001b[39m pathlib\u001b[38;5;241m.\u001b[39mPath(__main__\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__file__\u001b[39m)\u001b[38;5;241m.\u001b[39mresolve()\n\u001b[0;32m    715\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(abs_main_path\u001b[38;5;241m.\u001b[39mparent)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module '__main__' has no attribute '__file__'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInternalHashError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 253\u001b[0m\n\u001b[0;32m    250\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m voisins\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 253\u001b[0m     main()\n",
      "Cell \u001b[1;32mIn[5], line 18\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m():\n\u001b[0;32m     17\u001b[0m     init \u001b[38;5;241m=\u001b[39m st\u001b[38;5;241m.\u001b[39mmarkdown(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*Initialisation de l\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mapplication en cours...*\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 18\u001b[0m     init \u001b[38;5;241m=\u001b[39m st\u001b[38;5;241m.\u001b[39mmarkdown(init_api())\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;66;03m# Affichage du titre et du sous-titre\u001b[39;00m\n\u001b[0;32m     21\u001b[0m     st\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImplémenter un modèle de scoring\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\streamlit\\runtime\\legacy_caching\\caching.py:715\u001b[0m, in \u001b[0;36mcache.<locals>.wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    713\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m show_spinner:\n\u001b[0;32m    714\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m spinner(message):\n\u001b[1;32m--> 715\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m get_or_create_cached_value()\n\u001b[0;32m    716\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    717\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m get_or_create_cached_value()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\streamlit\\runtime\\legacy_caching\\caching.py:637\u001b[0m, in \u001b[0;36mcache.<locals>.wrapped_func.<locals>.get_or_create_cached_value\u001b[1;34m()\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01mnonlocal\u001b[39;00m cache_key\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    632\u001b[0m     \u001b[38;5;66;03m# Delay generating the cache key until the first call.\u001b[39;00m\n\u001b[0;32m    633\u001b[0m     \u001b[38;5;66;03m# This way we can see values of globals, including functions\u001b[39;00m\n\u001b[0;32m    634\u001b[0m     \u001b[38;5;66;03m# defined after this one.\u001b[39;00m\n\u001b[0;32m    635\u001b[0m     \u001b[38;5;66;03m# If we generated the key earlier we would only hash those\u001b[39;00m\n\u001b[0;32m    636\u001b[0m     \u001b[38;5;66;03m# globals by name, and miss changes in their code or value.\u001b[39;00m\n\u001b[1;32m--> 637\u001b[0m     cache_key \u001b[38;5;241m=\u001b[39m _hash_func(non_optional_func, hash_funcs)\n\u001b[0;32m    639\u001b[0m \u001b[38;5;66;03m# First, get the cache that's attached to this function.\u001b[39;00m\n\u001b[0;32m    640\u001b[0m \u001b[38;5;66;03m# This cache's key is generated (above) from the function's code.\u001b[39;00m\n\u001b[0;32m    641\u001b[0m mem_cache \u001b[38;5;241m=\u001b[39m _mem_caches\u001b[38;5;241m.\u001b[39mget_cache(cache_key, max_entries, ttl)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\streamlit\\runtime\\legacy_caching\\caching.py:767\u001b[0m, in \u001b[0;36m_hash_func\u001b[1;34m(func, hash_funcs)\u001b[0m\n\u001b[0;32m    756\u001b[0m update_hash(\n\u001b[0;32m    757\u001b[0m     (func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m, func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m),\n\u001b[0;32m    758\u001b[0m     hasher\u001b[38;5;241m=\u001b[39mfunc_hasher,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    761\u001b[0m     hash_source\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m    762\u001b[0m )\n\u001b[0;32m    764\u001b[0m \u001b[38;5;66;03m# Include the function's body in the hash. We *do* pass hash_funcs here,\u001b[39;00m\n\u001b[0;32m    765\u001b[0m \u001b[38;5;66;03m# because this step will be hashing any objects referenced in the function\u001b[39;00m\n\u001b[0;32m    766\u001b[0m \u001b[38;5;66;03m# body.\u001b[39;00m\n\u001b[1;32m--> 767\u001b[0m update_hash(\n\u001b[0;32m    768\u001b[0m     func,\n\u001b[0;32m    769\u001b[0m     hasher\u001b[38;5;241m=\u001b[39mfunc_hasher,\n\u001b[0;32m    770\u001b[0m     hash_funcs\u001b[38;5;241m=\u001b[39mhash_funcs,\n\u001b[0;32m    771\u001b[0m     hash_reason\u001b[38;5;241m=\u001b[39mHashReason\u001b[38;5;241m.\u001b[39mCACHING_FUNC_BODY,\n\u001b[0;32m    772\u001b[0m     hash_source\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m    773\u001b[0m )\n\u001b[0;32m    774\u001b[0m cache_key \u001b[38;5;241m=\u001b[39m func_hasher\u001b[38;5;241m.\u001b[39mhexdigest()\n\u001b[0;32m    775\u001b[0m _LOGGER\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[0;32m    776\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmem_cache key for \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m, func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m, cache_key\n\u001b[0;32m    777\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\streamlit\\runtime\\legacy_caching\\hashing.py:108\u001b[0m, in \u001b[0;36mupdate_hash\u001b[1;34m(val, hasher, hash_reason, hash_source, context, hash_funcs)\u001b[0m\n\u001b[0;32m    105\u001b[0m hash_stacks\u001b[38;5;241m.\u001b[39mcurrent\u001b[38;5;241m.\u001b[39mhash_source \u001b[38;5;241m=\u001b[39m hash_source\n\u001b[0;32m    107\u001b[0m ch \u001b[38;5;241m=\u001b[39m _CodeHasher(hash_funcs)\n\u001b[1;32m--> 108\u001b[0m ch\u001b[38;5;241m.\u001b[39mupdate(hasher, val, context)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\streamlit\\runtime\\legacy_caching\\hashing.py:385\u001b[0m, in \u001b[0;36m_CodeHasher.update\u001b[1;34m(self, hasher, obj, context)\u001b[0m\n\u001b[0;32m    383\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate\u001b[39m(\u001b[38;5;28mself\u001b[39m, hasher, obj: Any, context: Optional[Context] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Update the provided hasher with the hash of an object.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 385\u001b[0m     b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_bytes(obj, context)\n\u001b[0;32m    386\u001b[0m     hasher\u001b[38;5;241m.\u001b[39mupdate(b)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\streamlit\\runtime\\legacy_caching\\hashing.py:374\u001b[0m, in \u001b[0;36m_CodeHasher.to_bytes\u001b[1;34m(self, obj, context)\u001b[0m\n\u001b[0;32m    371\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m    373\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[1;32m--> 374\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InternalHashError(ex, obj)\n\u001b[0;32m    376\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    377\u001b[0m     \u001b[38;5;66;03m# In case an UnhashableTypeError (or other) error is thrown, clean up the\u001b[39;00m\n\u001b[0;32m    378\u001b[0m     \u001b[38;5;66;03m# stack so we don't get false positives in future hashing calls\u001b[39;00m\n\u001b[0;32m    379\u001b[0m     hash_stacks\u001b[38;5;241m.\u001b[39mcurrent\u001b[38;5;241m.\u001b[39mpop()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\streamlit\\runtime\\legacy_caching\\hashing.py:360\u001b[0m, in \u001b[0;36m_CodeHasher.to_bytes\u001b[1;34m(self, obj, context)\u001b[0m\n\u001b[0;32m    356\u001b[0m hash_stacks\u001b[38;5;241m.\u001b[39mcurrent\u001b[38;5;241m.\u001b[39mpush(obj)\n\u001b[0;32m    358\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    359\u001b[0m     \u001b[38;5;66;03m# Hash the input\u001b[39;00m\n\u001b[1;32m--> 360\u001b[0m     b \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (tname, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_to_bytes(obj, context))\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;66;03m# Hmmm... It's possible that the size calculation is wrong. When we\u001b[39;00m\n\u001b[0;32m    363\u001b[0m     \u001b[38;5;66;03m# call to_bytes inside _to_bytes things get double-counted.\u001b[39;00m\n\u001b[0;32m    364\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mgetsizeof(b)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\streamlit\\runtime\\legacy_caching\\hashing.py:626\u001b[0m, in \u001b[0;36m_CodeHasher._to_bytes\u001b[1;34m(self, obj, context)\u001b[0m\n\u001b[0;32m    624\u001b[0m code \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__code__\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m code \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 626\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file_should_be_hashed(code\u001b[38;5;241m.\u001b[39mco_filename):\n\u001b[0;32m    627\u001b[0m     context \u001b[38;5;241m=\u001b[39m _get_context(obj)\n\u001b[0;32m    628\u001b[0m     defaults \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__defaults__\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\streamlit\\runtime\\legacy_caching\\hashing.py:402\u001b[0m, in \u001b[0;36m_CodeHasher._file_should_be_hashed\u001b[1;34m(self, filename)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file_is_blacklisted:\n\u001b[0;32m    400\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m file_util\u001b[38;5;241m.\u001b[39mfile_is_in_folder_glob(\n\u001b[1;32m--> 402\u001b[0m     filepath, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_main_script_directory()\n\u001b[0;32m    403\u001b[0m ) \u001b[38;5;129;01mor\u001b[39;00m file_util\u001b[38;5;241m.\u001b[39mfile_in_pythonpath(filepath)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\streamlit\\runtime\\legacy_caching\\hashing.py:714\u001b[0m, in \u001b[0;36m_CodeHasher._get_main_script_directory\u001b[1;34m()\u001b[0m\n\u001b[0;32m    710\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01m__main__\u001b[39;00m\n\u001b[0;32m    712\u001b[0m \u001b[38;5;66;03m# This works because we set __main__.__file__ to the\u001b[39;00m\n\u001b[0;32m    713\u001b[0m \u001b[38;5;66;03m# script path in ScriptRunner.\u001b[39;00m\n\u001b[1;32m--> 714\u001b[0m abs_main_path \u001b[38;5;241m=\u001b[39m pathlib\u001b[38;5;241m.\u001b[39mPath(__main__\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__file__\u001b[39m)\u001b[38;5;241m.\u001b[39mresolve()\n\u001b[0;32m    715\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(abs_main_path\u001b[38;5;241m.\u001b[39mparent)\n",
      "\u001b[1;31mInternalHashError\u001b[0m: module '__main__' has no attribute '__file__'\n\nWhile caching the body of `init_api()`, Streamlit encountered an\nobject of type `builtins.function`, which it does not know how to hash.\n\n**In this specific case, it's very likely you found a Streamlit bug so please\n[file a bug report here.]\n(https://github.com/streamlit/streamlit/issues/new/choose)**\n\nIn the meantime, you can try bypassing this error by registering a custom\nhash function via the `hash_funcs` keyword in @st.cache(). For example:\n\n```\n@st.cache(hash_funcs={builtins.function: my_hash_func})\ndef my_func(...):\n    ...\n```\n\nIf you don't know where the object of type `builtins.function` is coming\nfrom, try looking at the hash chain below for an object that you do recognize,\nthen pass that to `hash_funcs` instead:\n\n```\nObject of type builtins.function: <function init_api at 0x00000160459B39C0>\n```\n\nPlease see the `hash_funcs` [documentation](https://docs.streamlit.io/library/advanced-features/caching#the-hash_funcs-parameter)\nfor more details.\n            "
     ]
    }
   ],
   "source": [
    "\n",
    "import streamlit as st\n",
    "\n",
    "import requests\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from flask import Flask\n",
    "\n",
    "\n",
    "URL_API = \"http://localhost:5000/\"\n",
    "\n",
    "def main():\n",
    "\n",
    "    init = st.markdown(\"*Initialisation de l'application en cours...*\")\n",
    "    init = st.markdown(init_api())\n",
    "\n",
    "    # Affichage du titre et du sous-titre\n",
    "    st.title(\"Implémenter un modèle de scoring\")\n",
    "    st.markdown(\"<i>API répondant aux besoins du projet 7 pour le parcours Data Scientist OpenClassRoom</i>\", unsafe_allow_html=True)\n",
    "\n",
    "    # Affichage d'informations dans la sidebar\n",
    "    st.sidebar.subheader(\"Informations générales\")\n",
    "    # Chargement du logo\n",
    "    logo = load_logo()\n",
    "    st.sidebar.image(logo,\n",
    "                     width=200)\n",
    "\n",
    "    # Chargement de la selectbox\n",
    "    lst_id = load_selectbox()\n",
    "    global id_client\n",
    "    id_client = st.sidebar.selectbox(\"ID Client\", lst_id)\n",
    "    \n",
    "    # Chargement des infos générales\n",
    "    nb_credits, rev_moy, credits_moy, targets = load_infos_gen()\n",
    "\n",
    "    # Affichage des infos dans la sidebar\n",
    "    # Nombre de crédits existants\n",
    "    st.sidebar.markdown(\"<u>Nombre crédits existants dans la base :</u>\", unsafe_allow_html=True)\n",
    "    st.sidebar.text(nb_credits)\n",
    "\n",
    "    # Graphique camembert\n",
    "    st.sidebar.markdown(\"<u>Différence solvabilité / non solvabilité</u>\", unsafe_allow_html=True)\n",
    "\n",
    "    plt.pie(targets, explode=[0, 0.1], labels=[\"Solvable\", \"Non solvable\"], autopct='%1.1f%%',\n",
    "            shadow=True, startangle=90)\n",
    "    st.sidebar.pyplot()\n",
    "\n",
    "    # Revenus moyens\n",
    "    st.sidebar.markdown(\"<u>Revenus moyens $(USD) :</u>\", unsafe_allow_html=True)\n",
    "    st.sidebar.text(rev_moy)\n",
    "\n",
    "    # Montant crédits moyen\n",
    "    st.sidebar.markdown(\"<u>Montant crédits moyen $(USD) :</u>\", unsafe_allow_html=True)\n",
    "    st.sidebar.text(credits_moy)\n",
    "    \n",
    "    # Affichage de l'ID client sélectionné\n",
    "    st.write(\"Vous avez sélectionné le client :\", id_client)\n",
    "\n",
    "    # Affichage état civil\n",
    "    st.header(\"**Informations client**\")\n",
    "    #infos = st.checkbox(\"Afficher les informations du client?\")\n",
    "\n",
    "    if st.checkbox(\"Afficher les informations du client?\"):\n",
    "        \n",
    "        infos_client = identite_client()\n",
    "        #st.write(\"Statut famille :**\", infos_client[\"status_famille\"], \"**\")\n",
    "        #st.write(\"Nombre d'enfant(s) :**\", infos_client[\"nb_enfant\"], \"**\")\n",
    "        #st.write(\"Age client :\", infos_client[\"age\"], \"ans.\")\n",
    "        st.write(\"Statut famille :**\", infos_client[\"NAME_FAMILY_STATUS\"][0], \"**\")\n",
    "        st.write(\"Nombre d'enfant(s) :**\", infos_client[\"CNT_CHILDREN\"][0], \"**\")\n",
    "        st.write(\"Age client :\", int(infos_client[\"DAYS_BIRTH\"].values / -365), \"ans.\")\n",
    "\n",
    "        data_age = load_age_population()\n",
    "        # Set the style of plots\n",
    "        plt.style.use('fivethirtyeight')\n",
    "        plt.figure(figsize=(9, 9))\n",
    "        # Plot the distribution of ages in years\n",
    "        plt.hist(data_age, edgecolor = 'k', bins = 25)\n",
    "        plt.axvline(int(infos_client[\"DAYS_BIRTH\"].values / -365), color=\"red\", linestyle=\":\")\n",
    "        plt.title('Age of Client')\n",
    "        plt.xlabel('Age (years)')\n",
    "        plt.ylabel('Count')\n",
    "        st.pyplot()\n",
    "\n",
    "        st.subheader(\"*Revenus*\")\n",
    "        #st.write(\"Total revenus client :\", infos_client[\"revenus\"], \"$\")\n",
    "        st.write(\"Total revenus client :\", infos_client[\"AMT_INCOME_TOTAL\"][0], \"$\")\n",
    "\n",
    "        data_revenus = load_revenus_population()\n",
    "        # Set the style of plots\n",
    "        plt.style.use('fivethirtyeight')\n",
    "        plt.figure(figsize=(9, 9))\n",
    "        # Plot the distribution of revenus\n",
    "        plt.hist(data_revenus, edgecolor = 'k')\n",
    "        plt.axvline(infos_client[\"AMT_INCOME_TOTAL\"][0], color=\"red\", linestyle=\":\")\n",
    "        plt.title('Revenus du Client')\n",
    "        plt.xlabel('Revenus ($ USD)')\n",
    "        plt.ylabel('Count')\n",
    "        st.pyplot()\n",
    "\n",
    "        #st.write(\"Montant du crédit :\", infos_client[\"montant_credit\"], \"$\")\n",
    "        #st.write(\"Annuités crédit :\", infos_client[\"annuites\"], \"$\")\n",
    "        #st.write(\"Montant du bien pour le crédit :\", infos_client[\"montant_bien\"], \"$\")\n",
    "        st.write(\"Montant du crédit :\", infos_client[\"AMT_CREDIT\"][0], \"$\")\n",
    "        st.write(\"Annuités crédit :\", infos_client[\"AMT_ANNUITY\"][0], \"$\")\n",
    "        st.write(\"Montant du bien pour le crédit :\", infos_client[\"AMT_GOODS_PRICE\"][0], \"$\")\n",
    "    else:\n",
    "        st.markdown(\"<i>Informations masquées</i>\", unsafe_allow_html=True)\n",
    "    \n",
    "    # Affichage solvabilité client\n",
    "    st.header(\"**Analyse dossier client**\")\n",
    "    \n",
    "    st.markdown(\"<u>Probabilité de risque de faillite du client :</u>\", unsafe_allow_html=True)\n",
    "    prediction = load_prediction()\n",
    "    st.write(round(prediction*100, 2), \"%\")\n",
    "    st.markdown(\"<u>Données client :</u>\", unsafe_allow_html=True)\n",
    "    st.write(identite_client()) \n",
    "\n",
    "    # Affichage des dossiers similaires\n",
    "    chk_voisins = st.checkbox(\"Afficher dossiers similaires?\")\n",
    "\n",
    "    if chk_voisins:\n",
    "        \n",
    "        similar_id = load_voisins()\n",
    "        st.markdown(\"<u>Liste des 10 dossiers les plus proches de ce client :</u>\", unsafe_allow_html=True)\n",
    "        st.write(similar_id)\n",
    "        st.markdown(\"<i>Target 1 = Client en faillite</i>\", unsafe_allow_html=True)\n",
    "    else:\n",
    "        st.markdown(\"<i>Informations masquées</i>\", unsafe_allow_html=True)\n",
    "\n",
    "\n",
    "@st.cache\n",
    "def init_api():\n",
    "\n",
    "    # Requête permettant de récupérer la liste des ID clients\n",
    "    init_api = requests.get(URL_API + \"init_model\")\n",
    "    init_api = init_api.json()\n",
    "\n",
    "    return \"Initialisation application terminée.\"\n",
    "\n",
    "@st.cache()\n",
    "def load_logo():\n",
    "    # Construction de la sidebar\n",
    "    # Chargement du logo\n",
    "    logo = Image.open(\"logo.png\") \n",
    "    \n",
    "    return logo\n",
    "\n",
    "@st.cache()\n",
    "def load_selectbox():\n",
    "    # Requête permettant de récupérer la liste des ID clients\n",
    "    data_json = requests.get(URL_API + \"load_data\")\n",
    "    data = data_json.json()\n",
    "\n",
    "    # Récupération des valeurs sans les [] de la réponse\n",
    "    lst_id = []\n",
    "    for i in data:\n",
    "        lst_id.append(i[0])\n",
    "\n",
    "    return lst_id\n",
    "\n",
    "@st.cache()\n",
    "def load_infos_gen():\n",
    "\n",
    "    # Requête permettant de récupérer :\n",
    "    # Le nombre de lignes de crédits existants dans la base\n",
    "    # Le revenus moyens des clients\n",
    "    # Le montant moyen des crédits existants\n",
    "    infos_gen = requests.get(URL_API + \"infos_gen\")\n",
    "    infos_gen = infos_gen.json()\n",
    "\n",
    "    nb_credits = infos_gen[0]\n",
    "    rev_moy = infos_gen[1]\n",
    "    credits_moy = infos_gen[2]\n",
    "\n",
    "    # Requête permettant de récupérer\n",
    "    # Le nombre de target dans la classe 0\n",
    "    # et la classe 1\n",
    "    targets = requests.get(URL_API + \"disparite_target\")    \n",
    "    targets = targets.json()\n",
    "\n",
    "\n",
    "    return nb_credits, rev_moy, credits_moy, targets\n",
    "\n",
    "\n",
    "def identite_client():\n",
    "\n",
    "    # Requête permettant de récupérer les informations du client sélectionné\n",
    "    infos_client = requests.get(URL_API + \"infos_client\", params={\"id_client\":id_client})\n",
    "    #infos_client = infos_client.json()\n",
    "    \n",
    "    # On transforme la réponse en dictionnaire python\n",
    "    infos_client = json.loads(infos_client.content.decode(\"utf-8\"))\n",
    "    \n",
    "    # On transforme le dictionnaire en dataframe\n",
    "    infos_client = pd.DataFrame.from_dict(infos_client).T\n",
    "\n",
    "    return infos_client\n",
    "\n",
    "@st.cache\n",
    "def load_age_population():\n",
    "    \n",
    "    # Requête permettant de récupérer les âges de la \n",
    "    # population pour le graphique situant le client\n",
    "    data_age_json = requests.get(URL_API + \"load_age_population\")\n",
    "    data_age = data_age_json.json()\n",
    "\n",
    "    return data_age\n",
    "\n",
    "@st.cache\n",
    "def load_revenus_population():\n",
    "    \n",
    "    # Requête permettant de récupérer des tranches de revenus \n",
    "    # de la population pour le graphique situant le client\n",
    "    data_revenus_json = requests.get(URL_API + \"load_revenus_population\")\n",
    "    \n",
    "    data_revenus = data_revenus_json.json()\n",
    "\n",
    "    return data_revenus\n",
    "\n",
    "def load_prediction():\n",
    "    \n",
    "    # Requête permettant de récupérer la prédiction\n",
    "    # de faillite du client sélectionné\n",
    "    prediction = requests.get(URL_API + \"predict\", params={\"id_client\":id_client})\n",
    "    prediction = prediction.json()\n",
    "\n",
    "    return prediction[1]\n",
    "\n",
    "def load_voisins():\n",
    "    \n",
    "    # Requête permettant de récupérer les 10 dossiers\n",
    "    # les plus proches de l'ID client choisi\n",
    "    voisins = requests.get(URL_API + \"load_voisins\", params={\"id_client\":id_client})\n",
    "\n",
    "    # On transforme la réponse en dictionnaire python\n",
    "    voisins = json.loads(voisins.content.decode(\"utf-8\"))\n",
    "    \n",
    "    # On transforme le dictionnaire en dataframe\n",
    "    voisins = pd.DataFrame.from_dict(voisins).T\n",
    "\n",
    "    # On déplace la colonne TARGET en premier pour plus de lisibilité\n",
    "    target = voisins[\"TARGET\"]\n",
    "    voisins.drop(labels=[\"TARGET\"], axis=1, inplace=True)\n",
    "    voisins.insert(0, \"TARGET\", target)\n",
    "    \n",
    "    return voisins\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6cb336c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: streamlit\n",
      "Version: 1.27.2\n",
      "Summary: A faster way to build and share data apps\n",
      "Home-page: https://streamlit.io\n",
      "Author: Snowflake Inc\n",
      "Author-email: hello@streamlit.io\n",
      "License: Apache License 2.0\n",
      "Location: C:\\Users\\Zbook\\AppData\\Roaming\\Python\\Python311\\site-packages\n",
      "Requires: altair, blinker, cachetools, click, gitpython, importlib-metadata, numpy, packaging, pandas, pillow, protobuf, pyarrow, pydeck, python-dateutil, requests, rich, tenacity, toml, tornado, typing-extensions, tzlocal, validators, watchdog\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show streamlit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbdfc15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
